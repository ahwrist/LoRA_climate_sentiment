{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35354cd",
   "metadata": {},
   "source": [
    "# Lightweight Fine-Tuning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560fb3ff",
   "metadata": {},
   "source": [
    "This Jupyter Notebook investigates the effectiveness of different fine-tuning techniques for a text classification task. We will compare the performance of three models on the task of classifying SMS messages as spam or not spam:\n",
    "\n",
    "Base Model: The pre-trained GPT-2 model from Hugging Face, without any fine-tuning.\n",
    "Fully Fine-Tuned Model: A GPT-2 model fine-tuned on the sms_spam dataset from Hugging Face.\n",
    "LoRA Fine-Tuned Model: A GPT-2 model fine-tuned on the sms_spam dataset using the Low-Rank Adaptation (LoRA) technique, a Parameter-Efficient Fine-Tuning (PEFT) method.\n",
    "We will leverage the datasets library from Hugging Face to load the sms_spam dataset and utilize the accuracy metric from the datasets library to evaluate the performance of each model.\n",
    "\n",
    "This exploration aims to assess whether more efficient fine-tuning matches or improves classification accuracy on the SMS spam task and, if so, whether LoRA offers a more efficient fine-tuning approach compared to full fine-tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d76bb",
   "metadata": {},
   "source": [
    "## Loading and Evaluating a Foundation Model\n",
    "\n",
    "In this section, we load the pre-trained GPT2 Hugging Face model and evaluate its performance prior to fine-tuning. This step includes loading an appropriate tokenizer and dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4935cb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the required versino of datasets if needed (uncomment to run)\n",
    "# You may need to restart the kernel after running this cell\n",
    "# ! pip install -q \"datasets==2.15.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40c09ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrewwrist/Documents/Projects/AI_ML/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset from Hugging Face\n",
    "dataset = load_dataset(\"sms_spam\")\n",
    "\n",
    "# Get the raw dataset\n",
    "raw_dataset = dataset['train']  # Assuming you want to work with the 'train' split\n",
    "\n",
    "# Split the dataset into training and testing subsets\n",
    "train_data, test_data = train_test_split(raw_dataset, test_size=0.2, random_state=42)  # You can adjust test_size and random_state as needed\n",
    "\n",
    "# Convert the split data into Dataset objects\n",
    "train_dataset = Dataset.from_dict(train_data)\n",
    "test_dataset = Dataset.from_dict(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70c2c2ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sms': \"FREE2DAY sexy St George's Day pic of Jordan!Txt PIC to 89080 dont miss out, then every wk a saucy celeb!4 more pics c PocketBabe.co.uk 0870241182716 £3/wk\\n\",\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the first element. For labels, 0 is not spam and 1 is spam\n",
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b04a05",
   "metadata": {},
   "source": [
    "### Pre-process datasets\n",
    "The dataset needs to be processed by converting all of the text into tokens for the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "019b9f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "# Load GPT2 tokenizer\n",
    "gpt2_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "gpt2_tokenizer.pad_token = gpt2_tokenizer.eos_token  # Assign padding token\n",
    "gpt2_tokenizer.build_inputs_with_special_tokens(gpt2_tokenizer.all_special_tokens)  # Rebuild vocabulary\n",
    " \n",
    "def tokenize_dataset(dataset):\n",
    "    '''\n",
    "    Summary: Tokenize dataset for downstream LLM training and inference\n",
    "    Input: Un-tokenized dataset\n",
    "    Output: Tokenized dataset\n",
    "    '''\n",
    "    tokenized_dataset = dataset.map(\n",
    "        lambda x: gpt2_tokenizer(x['sms'], truncation=True), batched=True\n",
    "    )\n",
    "    return tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fdfe669",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 4459/4459 [00:00<00:00, 11899.21 examples/s]\n",
      "Map: 100%|██████████| 1115/1115 [00:00<00:00, 10342.54 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the train and test datasets\n",
    "train_tokenized = tokenize_dataset(train_dataset)\n",
    "test_tokenized = tokenize_dataset(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97026c1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sms', 'label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 4459\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect train dataset\n",
    "train_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fb325336",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2ForSequenceClassification\n",
    "\n",
    "def load_gpt2_model():\n",
    "    '''\n",
    "    Summary: load the GPT2 base model for training, modification, and inference\n",
    "    Output: GPT2 base model\n",
    "    '''\n",
    "    gpt2_model_base = GPT2ForSequenceClassification.from_pretrained(\n",
    "        'gpt2',\n",
    "        num_labels=2,\n",
    "        id2label={0: 'not_spam', 1: 'spam'}, # In the dataset, 0 is not spam, and 1 is spam\n",
    "        label2id={'not_spam': 0, 'spam': 1}\n",
    "    )\n",
    "\n",
    "    # Freeze all the parameters of the base model using param.requires_grad = False\n",
    "    # more info here: https://huggingface.co/transformers/v4.2.2/training.html\n",
    "    for param in gpt2_model_base.base_model.parameters():\n",
    "        param.requires_grad = True\n",
    "    return gpt2_model_base\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0962297e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "gpt2_model_base = load_gpt2_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f107daaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=768, out_features=2, bias=False)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use model.score to output the final classification layer for GPT2. In others it may be model.classifier\n",
    "gpt2_model_base.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "18b8e897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2ForSequenceClassification(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(50257, 768)\n",
      "    (wpe): Embedding(1024, 768)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-11): 12 x GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): lora.Linear(\n",
      "            (base_layer): Conv1D()\n",
      "            (lora_dropout): ModuleDict(\n",
      "              (default): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (lora_A): ModuleDict(\n",
      "              (default): Linear(in_features=768, out_features=4, bias=False)\n",
      "            )\n",
      "            (lora_B): ModuleDict(\n",
      "              (default): Linear(in_features=4, out_features=2304, bias=False)\n",
      "            )\n",
      "            (lora_embedding_A): ParameterDict()\n",
      "            (lora_embedding_B): ParameterDict()\n",
      "          )\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (score): ModulesToSaveWrapper(\n",
      "    (original_module): Linear(in_features=768, out_features=2, bias=False)\n",
      "    (modules_to_save): ModuleDict(\n",
      "      (default): Linear(in_features=768, out_features=2, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Print full model parameters\n",
    "print(gpt2_model_base)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f168898",
   "metadata": {},
   "source": [
    "### Evaluate base model on test set\n",
    "\n",
    "Note that all of the training, testing, and inference for this project is performed locally on a CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568c4b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "import time\n",
    "\n",
    "# Set torch device to CPU for running on local CPU\n",
    "device = torch.device('cpu')\n",
    "metric = load_metric('accuracy', trust_remote_code=True)\n",
    "\n",
    "def predict(model, tokenized_dataset, pred_max_qty=50):\n",
    "  \"\"\"\n",
    "  Summmary: Function to make predictions on a specific split of the tokenized dataset\n",
    "  Input:\n",
    "    model: LLM model\n",
    "    tokenized_dataset: tokenized dataset\n",
    "    pred_max_qty: maximum quantity of predictions to predict labels for\n",
    "  Output:\n",
    "    predictions: list of predictions\n",
    "    labels: labels from initial dataset\n",
    "    accuracy: accuracy of predictions vs labels from dataset\n",
    "    execution_time: amount of time to make predictions\n",
    "  \"\"\"\n",
    "  model = model.to(device)\n",
    "  start_time = time.time()\n",
    "  predictions = [] # Collect predictions\n",
    "  labels = [] # Collect true labels for evaluation\n",
    "  for i, datapoint in enumerate(test_tokenized):\n",
    "    if i >= pred_max_qty:\n",
    "      break\n",
    "    input_ids = torch.tensor([datapoint[\"input_ids\"]]).to(device)\n",
    "    attention_mask = torch.tensor([datapoint[\"attention_mask\"]]).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "      outputs = model(input_ids, attention_mask=attention_mask)\n",
    "      logits = outputs.logits\n",
    "      predicted_label_index = torch.argmax(logits, dim=-1)\n",
    "      predicted_label = model.config.id2label[predicted_label_index.item()]\n",
    "      predictions.append(predicted_label_index.item())\n",
    "      labels.append(datapoint['label'])\n",
    "      \n",
    "  # # Use converted integer labels for metric calculation\n",
    "  metric.add_batch(predictions=predictions, references=labels)\n",
    "  accuracy = metric.compute()\n",
    "  end_time = time.time()\n",
    "  execution_time = end_time - start_time\n",
    "\n",
    "  return predictions, labels, accuracy, execution_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3fc807a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Accuracy:  {'accuracy': 0.4506283662477558}\n",
      "Execution Time:  38.88341784477234\n"
     ]
    }
   ],
   "source": [
    "gpt2_base_predictions, gpt2_base_labels, gpt2_base_accuracy, gpt2_base_execution_time = predict(gpt2_model_base, test_tokenized, pred_max_qty=1114)\n",
    "print(\"Test Set Accuracy: \", gpt2_base_accuracy)\n",
    "print(\"Execution Time: \", gpt2_base_execution_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cfd900",
   "metadata": {},
   "source": [
    "The base GPT2 model had an accuracy of 45%. Let's see if we can improve on that with full fine tuning and parameter efficient fine tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659ffd25",
   "metadata": {},
   "source": [
    "### Train model without Fine-Tuning\n",
    "\n",
    "In this section, the GPT2 base model is fully fine-tuned using the sms_spam dataset. Execution time and accuracy will be recorded to compare with parameter efficient fine-tuning later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51c46b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 501/4459 [02:57<21:32,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8707, 'grad_norm': 0.010503172874450684, 'learning_rate': 0.0017757344696120207, 'epoch': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 1000/4459 [05:40<17:45,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5157, 'grad_norm': 0.03326600044965744, 'learning_rate': 0.0015514689392240413, 'epoch': 0.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 1500/4459 [08:35<17:58,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3116, 'grad_norm': 0.027887722477316856, 'learning_rate': 0.001327203408836062, 'epoch': 0.34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 2000/4459 [11:45<17:54,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3003, 'grad_norm': 0.010177884250879288, 'learning_rate': 0.0011029378784480825, 'epoch': 0.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 2500/4459 [14:50<11:56,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1972, 'grad_norm': 0.0015331185422837734, 'learning_rate': 0.0008786723480601032, 'epoch': 0.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 3000/4459 [17:52<08:53,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1255, 'grad_norm': 0.005527514964342117, 'learning_rate': 0.0006544068176721239, 'epoch': 0.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 3500/4459 [21:00<05:37,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.218, 'grad_norm': 0.022273581475019455, 'learning_rate': 0.00043014128728414443, 'epoch': 0.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 4000/4459 [23:59<02:42,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1455, 'grad_norm': 0.004164999816566706, 'learning_rate': 0.00020587575689616505, 'epoch': 0.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "100%|██████████| 4459/4459 [29:03<00:00,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8658758401870728, 'eval_accuracy': 0.8654708520179372, 'eval_runtime': 139.8593, 'eval_samples_per_second': 7.972, 'eval_steps_per_second': 7.972, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4459/4459 [29:06<00:00,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1746.7713, 'train_samples_per_second': 2.553, 'train_steps_per_second': 2.553, 'train_loss': 0.31658849311960363, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time as time\n",
    "from transformers import DataCollatorWithPadding, Trainer, TrainingArguments\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {'accuracy': (predictions == labels).mean()}\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Use HuggingFace Trainer class for training and evaluating mbase model\n",
    "gpt2_trainer = Trainer(\n",
    "    model=gpt2_model_base,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"./data/gpt2_sms_class\",\n",
    "        learning_rate=2e-3,\n",
    "        per_device_train_batch_size=1, # Keeping low for low memory\n",
    "        per_device_eval_batch_size=1,\n",
    "        num_train_epochs=1,\n",
    "        weight_decay=0.01,\n",
    "        evaluation_strategy='epoch',\n",
    "        save_strategy='epoch',\n",
    "        load_best_model_at_end=True,\n",
    "    ),\n",
    "    train_dataset=train_tokenized,\n",
    "    eval_dataset=test_tokenized,\n",
    "    tokenizer=gpt2_tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=gpt2_tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "gpt2_trainer.train()\n",
    "end_time = time.time()\n",
    "gpt2_full_train_execution_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dabb422d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1115/1115 [00:23<00:00, 48.44it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.8932196497917175,\n",
       " 'eval_accuracy': 0.863677130044843,\n",
       " 'eval_runtime': 23.0973,\n",
       " 'eval_samples_per_second': 48.274,\n",
       " 'eval_steps_per_second': 48.274,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt2_trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b79938d",
   "metadata": {},
   "source": [
    "Note that saved models are only saved locally. They are too large to save to Github."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "000b680a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_model.save_pretrained('gpt2_full_train_spam')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc46168",
   "metadata": {},
   "source": [
    "The fully fine-tuned GPT2 base model performed very well with a 99% accuracy. However, it took over 29 minutes to train on a CPU! Training time would decrease substantially on a GPU, but sometimes infrastructure may be lacking. Additionally, long training times from full fine-tuning and GPUs can be require a lot of energy. Parameter Efficient Fine Tuning (Peft) offers alternatives to potentially achieve similar or even better performance with much less training time. In the next section we'll focus on using LoRA to fine-tune the GPT2 model and see if we can achieve the same high level of accuracy with less training time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d52a229",
   "metadata": {},
   "source": [
    "## Performing Parameter-Efficient Fine-Tuning\n",
    "\n",
    "TODO: In the cells below, create a PEFT model from your loaded model, run a training loop, and save the PEFT model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f1d289c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Linear(in_features=768, out_features=2, bias=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt2_model_base = load_gpt2_model()\n",
    "gpt2_model_base.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c96ab36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 148,992 || all params: 124,590,336 || trainable%: 0.11958551905663052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrewwrist/Documents/Projects/AI_ML/venv/lib/python3.11/site-packages/peft/tuners/lora/layer.py:1059: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from transformers import DataCollatorWithPadding, Trainer, TrainingArguments\n",
    "from peft import LoraConfig, TaskType, get_peft_model, LoftQConfig\n",
    "\n",
    "# Define LoRA configuration\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS, # Set task type to sequence classification\n",
    "    r=4, # Set LoRA rank (number of low-rank adaptation matrices)\n",
    "    lora_alpha=1, # Set learning rate\n",
    "    lora_dropout=0.1, # Set dropout rate\n",
    ")\n",
    "\n",
    "# Create LoRA model\n",
    "lora_model = get_peft_model(gpt2_model_base, lora_config)\n",
    "\n",
    "lora_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2c2b60",
   "metadata": {},
   "source": [
    "Now, instead of training the full model, as we did in the full fine-tuning, we are only training 11.96% of the trainable parameters for LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3eb1dc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 501/4459 [01:02<05:59, 11.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5542, 'grad_norm': 2.3128361590352142e-06, 'learning_rate': 0.0017757344696120207, 'epoch': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 1002/4459 [01:48<05:02, 11.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1904, 'grad_norm': 2.759829476417508e-05, 'learning_rate': 0.0015514689392240413, 'epoch': 0.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 1501/4459 [02:34<04:17, 11.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1371, 'grad_norm': 0.025812074542045593, 'learning_rate': 0.001327203408836062, 'epoch': 0.34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 2002/4459 [03:21<04:18,  9.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0882, 'grad_norm': 3.5229041372986103e-07, 'learning_rate': 0.0011029378784480825, 'epoch': 0.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 2501/4459 [04:07<04:04,  8.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0918, 'grad_norm': 1.5261623047990724e-05, 'learning_rate': 0.0008786723480601032, 'epoch': 0.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 3001/4459 [04:51<02:04, 11.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0484, 'grad_norm': 5.067917300038971e-06, 'learning_rate': 0.0006544068176721239, 'epoch': 0.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 3501/4459 [05:37<01:21, 11.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0853, 'grad_norm': 0.00038298757863231003, 'learning_rate': 0.00043014128728414443, 'epoch': 0.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 4002/4459 [06:22<00:41, 11.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1006, 'grad_norm': 6.577976496835447e-10, 'learning_rate': 0.00020587575689616505, 'epoch': 0.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "100%|██████████| 4459/4459 [07:31<00:00, 11.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6739403009414673, 'eval_accuracy': 0.905829596412556, 'eval_runtime': 27.8562, 'eval_samples_per_second': 40.027, 'eval_steps_per_second': 40.027, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4459/4459 [07:32<00:00,  9.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 452.4709, 'train_samples_per_second': 9.855, 'train_steps_per_second': 9.855, 'train_loss': 0.15419702643261654, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define compute metrics for LoRA evaluation\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {'accuracy': (predictions == labels).mean()}\n",
    "\n",
    "start_time = time.time()\n",
    "# Use HuggingFace Trainer class for training and evaluating LoRA model\n",
    "lora_trainer = Trainer(\n",
    "    model=lora_model,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"./data/lora_gpt2\",\n",
    "        learning_rate=2e-3,\n",
    "        per_device_train_batch_size=1, # Keeping low for low memory\n",
    "        per_device_eval_batch_size=1,\n",
    "        num_train_epochs=1,\n",
    "        weight_decay=0.01,\n",
    "        evaluation_strategy='epoch',\n",
    "        save_strategy='epoch',\n",
    "        load_best_model_at_end=True,\n",
    "    ),\n",
    "    train_dataset=train_tokenized,\n",
    "    eval_dataset=test_tokenized,\n",
    "    tokenizer=gpt2_tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=gpt2_tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "lora_trainer.train()\n",
    "\n",
    "end_time = time.time()\n",
    "lora_train_execution_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c8b23fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1115/1115 [00:25<00:00, 43.38it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6740188598632812,\n",
       " 'eval_accuracy': 0.9049327354260089,\n",
       " 'eval_runtime': 26.4767,\n",
       " 'eval_samples_per_second': 42.113,\n",
       " 'eval_steps_per_second': 42.113,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67cd9a3",
   "metadata": {},
   "source": [
    "The LoRA model actually performed better than the full fine-tuned model in just a quarter of the time (7.5 minutes vs 29 minutes)! Not only are we saving time and improving performance with this PEFT technique, but we're also saving valuable computational and energy resources. In the next section, we will investigate further by performing inference and visually comparing the three models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa7fe003",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_model.save_pretrained('gpt2_lora_email_spam')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615b12c6",
   "metadata": {},
   "source": [
    "## Performing Inference with a PEFT Model\n",
    "\n",
    "In this section, we will load the saved PEFT model weights and evaluate the performance of the trained PEFT model and offer a visual comparison of performance against the other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "863ec66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from peft import PeftModelForSequenceClassification\n",
    "from transformers import AutoModelForSequenceClassification, DefaultDataCollator\n",
    "from transformers import GPT2Config\n",
    "# lora_model_out = AutoModelForSequenceClassification.from_pretrained('gpt2_lora_email_spam')\n",
    "\n",
    "# Configure saved LoRA model for loading\n",
    "lora_config = GPT2Config.from_pretrained('gpt2_lora_email_spam/adapter_config.json')\n",
    "\n",
    "# Add padding token\n",
    "lora_config.pad_token_id = lora_config.eos_token_id\n",
    "\n",
    "# Load saved LoRA model\n",
    "lora_model_out = GPT2ForSequenceClassification.from_pretrained('gpt2_lora_email_spam', config = lora_config)\n",
    "\n",
    "# Add padding token to the tokenizer\n",
    "gpt2_tokenizer.pad_token = gpt2_tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0ef3fc17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Accuracy:  {'accuracy': 0.9937163375224417}\n",
      "Execution Time:  40.78544282913208\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set and calculate accuracy\n",
    "lora_predictions, lora_labels, lora_accuracy, lora_execution_time = predict(lora_model_out, test_tokenized, pred_max_qty=1114)\n",
    "print(\"Test Set Accuracy: \", lora_accuracy)\n",
    "print(\"Execution Time: \", lora_execution_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "449809e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Accuracy:  {'accuracy': 0.9901256732495511}\n",
      "Execution Time:  40.30510878562927\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set and calculate accuracy\n",
    "gpt2_fulltrain_predictions, gpt2_fulltrain_labels, gpt2_fulltrain_accuracy, gpt2_fulltrain_execution_time = predict(gpt2_model, test_tokenized, pred_max_qty=1114)\n",
    "# print(\"Test Set Predictions: \", base_predictions)\n",
    "# print(\"Test Set Labels: \", base_labels)\n",
    "print(\"Test Set Accuracy: \", gpt2_fulltrain_accuracy)\n",
    "print(\"Execution Time: \", gpt2_fulltrain_execution_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "81f430ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sms</th>\n",
       "      <th>labels</th>\n",
       "      <th>gpt2_base_predictions</th>\n",
       "      <th>gpt2_full_tune</th>\n",
       "      <th>LoRA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kit Strip - you have been billed 150p. Netcollex Ltd. PO Box 1013 IG11 OJA\\n</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>URGENT This is our 2nd attempt to contact U. Your £900 prize from YESTERDAY is still awaiting collection. To claim CALL NOW 09061702893. ACL03530150PM\\n</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Some friends want me to drive em someplace, probably take a while\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dunno y u ask me.\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Call Germany for only 1 pence per minute! Call from a fixed line via access number 0844 861 85 85. No prepayment. Direct access!\\n</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Yes princess! I want to catch you with my big strong hands...\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dear,shall mail tonite.busy in the street,shall update you tonite.things are looking ok.varunnathu edukkukayee raksha ollu.but a good one in real sense.\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(You didn't hear it from me)\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I promise to take good care of you, princess. I have to run now. Please send pics when you get a chance. Ttyl!\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>all the lastest from Stereophonics, Marley, Dizzee Racal, Libertines and The Strokes! Win Nookii games with Flirt!! Click TheMob WAP Bookmark or text WAP to 82468\\n</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                    sms  \\\n",
       "0                                                                                          Kit Strip - you have been billed 150p. Netcollex Ltd. PO Box 1013 IG11 OJA\\n   \n",
       "1              URGENT This is our 2nd attempt to contact U. Your £900 prize from YESTERDAY is still awaiting collection. To claim CALL NOW 09061702893. ACL03530150PM\\n   \n",
       "2                                                                                                   Some friends want me to drive em someplace, probably take a while\\n   \n",
       "3                                                                                                                                                   Dunno y u ask me.\\n   \n",
       "4                                    Call Germany for only 1 pence per minute! Call from a fixed line via access number 0844 861 85 85. No prepayment. Direct access!\\n   \n",
       "5                                                                                                       Yes princess! I want to catch you with my big strong hands...\\n   \n",
       "6            Dear,shall mail tonite.busy in the street,shall update you tonite.things are looking ok.varunnathu edukkukayee raksha ollu.but a good one in real sense.\\n   \n",
       "7                                                                                                                                        (You didn't hear it from me)\\n   \n",
       "8                                                      I promise to take good care of you, princess. I have to run now. Please send pics when you get a chance. Ttyl!\\n   \n",
       "9  all the lastest from Stereophonics, Marley, Dizzee Racal, Libertines and The Strokes! Win Nookii games with Flirt!! Click TheMob WAP Bookmark or text WAP to 82468\\n   \n",
       "\n",
       "   labels  gpt2_base_predictions  gpt2_full_tune  LoRA  \n",
       "0       1                      1               1     1  \n",
       "1       1                      1               1     1  \n",
       "2       0                      1               0     0  \n",
       "3       0                      1               0     0  \n",
       "4       1                      1               1     1  \n",
       "5       0                      1               0     0  \n",
       "6       0                      0               1     0  \n",
       "7       0                      1               0     0  \n",
       "8       0                      0               0     0  \n",
       "9       1                      1               1     1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "review_count = slice(26, 36) # Define a slice that has a good mix of spam and not spam\n",
    "review_set = test_tokenized[review_count]\n",
    "\n",
    "# Set up dataframe to compare labels and predictions with SMS messages from the test dataset\n",
    "df_review = pd.DataFrame(\n",
    "    {\n",
    "        'sms': [item for item in review_set['sms']],\n",
    "        'labels': [item for item in review_set['label']],\n",
    "        'gpt2_base_predictions': gpt2_base_predictions[review_count],\n",
    "        'gpt2_full_tune': gpt2_fulltrain_predictions[review_count],\n",
    "        'LoRA': lora_predictions[review_count]\n",
    "        \n",
    "    }\n",
    ")\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "display(df_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27380e8",
   "metadata": {},
   "source": [
    "This selection of 10 spam messages was selected as it was a fairly even distribution between spam (1) and not spam (0). You can observe in the selection of SMS examples above, that LoRA perfromed very well, with 100% accuracy across the SMS messages, correctly identifying 4 of the spam messages as spam. the fully-tuned GPT2 model predicted one extra spam message, while the base model, significantly overpredicted, labeling 4 incorrectly as spam. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c4d13177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set train times for plot\n",
    "gpt2_full_train_time = 29 * 60\n",
    "LoRA_train_time = 7.5 * 60\n",
    "gpt2_base_train_time = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4ad01095",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dz/71j5m95x01d2wwbm3pz62vz80000gn/T/ipykernel_11896/4128727213.py:27: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax1.set_xticklabels(x_times, rotation=45)  # Set labels and rotate\n",
      "/var/folders/dz/71j5m95x01d2wwbm3pz62vz80000gn/T/ipykernel_11896/4128727213.py:38: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax2.set_xticklabels(x_accuracies, rotation=45)  # Set labels and rotate\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Training times (seconds)\n",
    "training_times = {\n",
    "    # 'Base model': gpt2_base_train_time,\n",
    "    'Full fine-tuning': gpt2_full_train_time,\n",
    "    'LoRA': LoRA_train_time\n",
    "}\n",
    "\n",
    "# Accuracies\n",
    "accuracies = {\n",
    "    'Full fine-tuning': gpt2_fulltrain_accuracy['accuracy'],\n",
    "    'LoRA': lora_accuracy['accuracy'],\n",
    "    'Base model': gpt2_base_accuracy['accuracy']\n",
    "    }\n",
    "\n",
    "# Create separate subplots for training times and accuracies\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 6))\n",
    "\n",
    "# Bar chart for training times\n",
    "x_times = training_times.keys()\n",
    "y_times = training_times.values()\n",
    "ax1.bar(x_times, y_times, color=['blue', 'green', 'orange'])\n",
    "ax1.set_title('Training Time (seconds)')\n",
    "ax1.set_xlabel('Fine-tuning Method')\n",
    "ax1.set_ylabel('Time (s)')\n",
    "ax1.set_xticklabels(x_times, rotation=45)  # Set labels and rotate\n",
    "\n",
    "\n",
    "# Bar chart for accuracies\n",
    "x_accuracies = accuracies.keys()\n",
    "y_accuracies = accuracies.values()\n",
    "# ax2.bar(x_labels, y_accuracies, color=['blue', 'green', 'orange'])\n",
    "ax2.bar(x_accuracies, y_accuracies, color=['blue', 'green', 'orange'])\n",
    "ax2.set_title('Accuracy')\n",
    "ax2.set_xlabel('Fine-tuning Method')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.set_xticklabels(x_accuracies, rotation=45)  # Set labels and rotate\n",
    "\n",
    "# Adjust layout and display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba10161e",
   "metadata": {},
   "source": [
    "Our experiments demonstrated that the Parameter-Efficient Fine-Tuning (PEFT) method using LoRA achieved comparable performance to full fine-tuning on the GPT-2 model for SMS spam classification on Hugging Face. Both models achieved 99% accuracy on the test set. However, the LoRA model required only a quarter of the training time compared to full fine-tuning. This significant reduction in training time translates to lower energy consumption. Notably, the base GPT-2 model, without fine-tuning, performed poorly on the task, achieving only 45% accuracy.Our experiments demonstrated that the Parameter-Efficient Fine-Tuning (PEFT) method using LoRA achieved comparable performance to full fine-tuning on the GPT-2 model for SMS spam classification on Hugging Face. Both models achieved 99% accuracy on the test set. However, the LoRA model required only a quarter of the training time compared to full fine-tuning. This significant reduction in training time translates to lower energy consumption. Notably, the base GPT-2 model, without fine-tuning, performed poorly on the task, achieving only 45% accuracy.\n",
    "\n",
    "\n",
    "This project was part of the Udacity Generative AI Nanodegree. Special thanks for Udacity for the training materials and making this work possible."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.7 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "6b5b525088d6332c5cf70b03a9f5e180ca0f3c63042aef5ed677c6c58b7b131a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
