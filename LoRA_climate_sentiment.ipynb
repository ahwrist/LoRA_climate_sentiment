{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35354cd",
   "metadata": {},
   "source": [
    "# Lightweight Fine-Tuning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560fb3ff",
   "metadata": {},
   "source": [
    "TODO: In this cell, describe your choices for each of the following\n",
    "\n",
    "* PEFT technique: \n",
    "* Model: \n",
    "* Evaluation approach: \n",
    "* Fine-tuning dataset: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d76bb",
   "metadata": {},
   "source": [
    "## Loading and Evaluating a Foundation Model\n",
    "\n",
    "TODO: In the cells below, load your chosen pre-trained Hugging Face model and evaluate its performance prior to fine-tuning. This step includes loading an appropriate tokenizer and dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f551c63a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Couldn't find a dataset script at /Users/andrewwrist/Documents/Projects/AI_ML/LoRA_climate_sentiment/climatebert/climatebert.py or any data file in the same directory. Couldn't find 'climatebert' on the Hugging Face Hub either: FileNotFoundError: Dataset 'climatebert' doesn't exist on the Hub. If the repo is private or gated, make sure to log in with `huggingface-cli login`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m device \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmps\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mbackends\u001b[39m.\u001b[39mmps\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[39m# Load dataset\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m dataset \u001b[39m=\u001b[39m load_dataset(\u001b[39m\"\u001b[39;49m\u001b[39mclimatebert\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mclimate_sentiment\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     11\u001b[0m \u001b[39m# Define labels\u001b[39;00m\n\u001b[1;32m     12\u001b[0m labels \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(dataset[\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mfeatures[\u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mnames)\n",
      "File \u001b[0;32m~/Documents/Projects/AI_ML/venv/lib/python3.11/site-packages/datasets/load.py:2128\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, token, use_auth_token, task, streaming, num_proc, storage_options, **config_kwargs)\u001b[0m\n\u001b[1;32m   2123\u001b[0m verification_mode \u001b[39m=\u001b[39m VerificationMode(\n\u001b[1;32m   2124\u001b[0m     (verification_mode \u001b[39mor\u001b[39;00m VerificationMode\u001b[39m.\u001b[39mBASIC_CHECKS) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m save_infos \u001b[39melse\u001b[39;00m VerificationMode\u001b[39m.\u001b[39mALL_CHECKS\n\u001b[1;32m   2125\u001b[0m )\n\u001b[1;32m   2127\u001b[0m \u001b[39m# Create a dataset builder\u001b[39;00m\n\u001b[0;32m-> 2128\u001b[0m builder_instance \u001b[39m=\u001b[39m load_dataset_builder(\n\u001b[1;32m   2129\u001b[0m     path\u001b[39m=\u001b[39;49mpath,\n\u001b[1;32m   2130\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m   2131\u001b[0m     data_dir\u001b[39m=\u001b[39;49mdata_dir,\n\u001b[1;32m   2132\u001b[0m     data_files\u001b[39m=\u001b[39;49mdata_files,\n\u001b[1;32m   2133\u001b[0m     cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m   2134\u001b[0m     features\u001b[39m=\u001b[39;49mfeatures,\n\u001b[1;32m   2135\u001b[0m     download_config\u001b[39m=\u001b[39;49mdownload_config,\n\u001b[1;32m   2136\u001b[0m     download_mode\u001b[39m=\u001b[39;49mdownload_mode,\n\u001b[1;32m   2137\u001b[0m     revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m   2138\u001b[0m     token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m   2139\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m   2140\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mconfig_kwargs,\n\u001b[1;32m   2141\u001b[0m )\n\u001b[1;32m   2143\u001b[0m \u001b[39m# Return iterable dataset in case of streaming\u001b[39;00m\n\u001b[1;32m   2144\u001b[0m \u001b[39mif\u001b[39;00m streaming:\n",
      "File \u001b[0;32m~/Documents/Projects/AI_ML/venv/lib/python3.11/site-packages/datasets/load.py:1814\u001b[0m, in \u001b[0;36mload_dataset_builder\u001b[0;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, use_auth_token, storage_options, **config_kwargs)\u001b[0m\n\u001b[1;32m   1812\u001b[0m     download_config \u001b[39m=\u001b[39m download_config\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m download_config \u001b[39melse\u001b[39;00m DownloadConfig()\n\u001b[1;32m   1813\u001b[0m     download_config\u001b[39m.\u001b[39mstorage_options\u001b[39m.\u001b[39mupdate(storage_options)\n\u001b[0;32m-> 1814\u001b[0m dataset_module \u001b[39m=\u001b[39m dataset_module_factory(\n\u001b[1;32m   1815\u001b[0m     path,\n\u001b[1;32m   1816\u001b[0m     revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m   1817\u001b[0m     download_config\u001b[39m=\u001b[39;49mdownload_config,\n\u001b[1;32m   1818\u001b[0m     download_mode\u001b[39m=\u001b[39;49mdownload_mode,\n\u001b[1;32m   1819\u001b[0m     data_dir\u001b[39m=\u001b[39;49mdata_dir,\n\u001b[1;32m   1820\u001b[0m     data_files\u001b[39m=\u001b[39;49mdata_files,\n\u001b[1;32m   1821\u001b[0m )\n\u001b[1;32m   1822\u001b[0m \u001b[39m# Get dataset builder class from the processing script\u001b[39;00m\n\u001b[1;32m   1823\u001b[0m builder_kwargs \u001b[39m=\u001b[39m dataset_module\u001b[39m.\u001b[39mbuilder_kwargs\n",
      "File \u001b[0;32m~/Documents/Projects/AI_ML/venv/lib/python3.11/site-packages/datasets/load.py:1507\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, **download_kwargs)\u001b[0m\n\u001b[1;32m   1505\u001b[0m                 \u001b[39mraise\u001b[39;00m e1 \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e1, \u001b[39mFileNotFoundError\u001b[39;00m):\n\u001b[0;32m-> 1507\u001b[0m                 \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m   1508\u001b[0m                     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCouldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt find a dataset script at \u001b[39m\u001b[39m{\u001b[39;00mrelative_to_absolute_path(combined_path)\u001b[39m}\u001b[39;00m\u001b[39m or any data file in the same directory. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1509\u001b[0m                     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCouldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt find \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpath\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m on the Hugging Face Hub either: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(e1)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00me1\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1510\u001b[0m                 ) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1511\u001b[0m             \u001b[39mraise\u001b[39;00m e1 \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1512\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Couldn't find a dataset script at /Users/andrewwrist/Documents/Projects/AI_ML/LoRA_climate_sentiment/climatebert/climatebert.py or any data file in the same directory. Couldn't find 'climatebert' on the Hugging Face Hub either: FileNotFoundError: Dataset 'climatebert' doesn't exist on the Hub. If the repo is private or gated, make sure to log in with `huggingface-cli login`."
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "\n",
    "# Check MPS availability using torch.backends.mps.is_available()\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset(\"climatebert\", \"climate_sentiment\")\n",
    "\n",
    "# Define labels\n",
    "labels = list(dataset[\"train\"].features[\"label\"].names)\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "model_ft = AutoModelForSequenceClassification.from_pretrained(\"gpt2\", num_labels=len(labels))\n",
    "model_lora = AutoModelForSequenceClassification.from_pretrained(\"gpt2\", num_labels=len(labels))\n",
    "\n",
    "# Define LoRA parameters\n",
    "lora_module = torch.nn.Linear(model_lora.base_model.wte.weight.shape[1], model_lora.base_model.wte.weight.shape[0])\n",
    "\n",
    "\n",
    "def lora_parameters(module):\n",
    "  if isinstance(module, torch.nn.Linear):\n",
    "    yield module.weight\n",
    "\n",
    "\n",
    "model_lora._modules[\"lora\"] = lora_module\n",
    "model_lora.lora.weight = torch.nn.Parameter(torch.randn(model_lora.base_model.wte.weight.shape[1], model_lora.base_model.wte.weight.shape[0]))\n",
    "\n",
    "\n",
    "def get_lora_optimizer(model):\n",
    "  return torch.optim.Adam([*lora_parameters(model), {\"params\": model.base_model.parameters(), \"lr\": 1e-5}])\n",
    "\n",
    "\n",
    "def get_full_ft_optimizer(model):\n",
    "  return torch.optim.Adam(model.parameters(), lr=2e-5)\n",
    "\n",
    "\n",
    "def compute_metrics(pred):\n",
    "  labels = pred.label_ids\n",
    "  preds = pred.predictions.argmax(-1)\n",
    "  acc = (labels == preds).sum().float() / len(labels)\n",
    "  return {\"accuracy\": acc}\n",
    "\n",
    "\n",
    "def train(model_name, model, optimizer, train_dataset, eval_dataset, epochs):\n",
    "  training_args = TrainingArguments(\n",
    "      output_dir=f\"./results/{model_name}\",\n",
    "      per_device_train_batch_size=8,\n",
    "      per_device_eval_batch_size=8,\n",
    "      num_train_epochs=epochs,\n",
    "      load_best_model_at_end=True,\n",
    "      metric_for_best_model=\"accuracy\",\n",
    "      logging_steps=50,\n",
    "      evaluation_strategy=\"epoch\",\n",
    "      fp16=True if device == \"mps\" else False,\n",
    "      eval_dataset=eval_dataset,\n",
    "      training_dataset=train_dataset,\n",
    "      # Leverage MPS for training and evaluation\n",
    "      gradient_accumulation_steps=2 if device == \"mps\" else 1,\n",
    "      place=\"mps\" if device == \"mps\" else device,\n",
    "  )\n",
    "\n",
    "  trainer = Trainer(\n",
    "      model=model,\n",
    "      args=training_args,\n",
    "      compute_metrics=compute_metrics,\n",
    "      train_dataset=train_dataset,\n",
    "      eval_dataset=eval_dataset,\n",
    "      optimizers=(optimizer, None),\n",
    "  )\n",
    "\n",
    "  trainer.train()\n",
    "  return trainer.evaluate(\"eval\")\n",
    "\n",
    "\n",
    "# Define training functions\n",
    "train_ft = lambda: train(\"full_ft\", model_ft.to(device), get_full_ft_optimizer(model_ft), dataset[\"train\"], dataset[\"test\"], 3)\n",
    "train_lora = lambda: train(\"lora\", model_lora.to(device), get_lora_optimizer(model_lora), dataset[\"train\"], dataset[\"test\"], 3)\n",
    "\n",
    "\n",
    "# Evaluate base model (untrained)\n",
    "def evaluate_base():\n",
    "  with torch.no_grad():\n",
    "    inputs = tokenizer(dataset[\"test\"], return_tensors=device)\n",
    "    outputs = model_ft.to(device)(**inputs)\n",
    "    preds = outputs.logits.argmax(-1)\n",
    "    acc = (preds == dataset[\"test\"][\"label\"]).sum().float() / len(preds)\n",
    "    print(f\"Base Model Accuracy: {acc}\")\n",
    "\n",
    "\n",
    "# Run Evaluations\n",
    "evaluate_base()\n",
    "print(train_ft())\n",
    "print(train_lora())\n",
    "\n",
    "# Inference Example\n",
    "text = \"Climate change presents a major risk to our planet.\"\n",
    "inputs = tokenizer(text, return_tensors=device)\n",
    "with torch.no_grad():\n",
    "  outputs = model_ft\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4935cb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "\n",
    "# Check MPS availability using torch.backends.mps.is_available()\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c424418a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f28c4a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = load_dataset(\"climatebert/climate_sentiment\")\n",
    "\n",
    "# Define labels\n",
    "labels = list(dataset[\"train\"].features[\"label\"].names)\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "model_ft = AutoModelForSequenceClassification.from_pretrained(\"gpt2\", num_labels=len(labels))\n",
    "model_lora = AutoModelForSequenceClassification.from_pretrained(\"gpt2\", num_labels=len(labels))\n",
    "\n",
    "# Define LoRA parameters\n",
    "lora_module = torch.nn.Linear(model_lora.base_model.wte.weight.shape[1], model_lora.base_model.wte.weight.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "019b9f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lora_parameters(module):\n",
    "  if isinstance(module, torch.nn.Linear):\n",
    "    yield module.weight\n",
    "\n",
    "\n",
    "model_lora._modules[\"lora\"] = lora_module\n",
    "model_lora.lora.weight = torch.nn.Parameter(torch.randn(model_lora.base_model.wte.weight.shape[1], model_lora.base_model.wte.weight.shape[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5176b07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lora_optimizer(model):\n",
    "  return torch.optim.Adam([*lora_parameters(model), {\"params\": model.base_model.parameters(), \"lr\": 1e-5}])\n",
    "\n",
    "\n",
    "def get_full_ft_optimizer(model):\n",
    "  return torch.optim.Adam(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a36d1308",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "  labels = pred.label_ids\n",
    "  preds = pred.predictions.argmax(-1)\n",
    "  acc = (labels == preds).sum().float() / len(labels)\n",
    "  return {\"accuracy\": acc}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d52a229",
   "metadata": {},
   "source": [
    "## Performing Parameter-Efficient Fine-Tuning\n",
    "\n",
    "TODO: In the cells below, create a PEFT model from your loaded model, run a training loop, and save the PEFT model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5775fadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model_name, model, optimizer, train_dataset, eval_dataset, epochs):\n",
    "  training_args = TrainingArguments(\n",
    "      output_dir=f\"./results/{model_name}\",\n",
    "      per_device_train_batch_size=8,\n",
    "      per_device_eval_batch_size=8,\n",
    "      num_train_epochs=epochs,\n",
    "      load_best_model_at_end=True,\n",
    "      metric_for_best_model=\"accuracy\",\n",
    "      logging_steps=50,\n",
    "      evaluation_strategy=\"epoch\",\n",
    "      fp16=True if device == \"mps\" else False,\n",
    "      eval_dataset=eval_dataset,\n",
    "      training_dataset=train_dataset,\n",
    "      # Leverage MPS for training and evaluation\n",
    "      gradient_accumulation_steps=2 if device == \"mps\" else 1,\n",
    "      place=\"mps\" if device == \"mps\" else device,\n",
    "  )\n",
    "\n",
    "  trainer = Trainer(\n",
    "      model=model,\n",
    "      args=training_args,\n",
    "      compute_metrics=compute_metrics,\n",
    "      train_dataset=train_dataset,\n",
    "      eval_dataset=eval_dataset,\n",
    "      optimizers=(optimizer, None),\n",
    "  )\n",
    "\n",
    "  trainer.train()\n",
    "  return trainer.evaluate(\"eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "894046c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training functions\n",
    "train_ft = lambda: train(\"full_ft\", model_ft.to(device), get_full_ft_optimizer(model_ft), dataset[\"train\"], dataset[\"test\"], 1)\n",
    "train_lora = lambda: train(\"lora\", model_lora.to(device), get_lora_optimizer(model_lora), dataset[\"train\"], dataset[\"test\"], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c4d4c908",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_base():\n",
    "  with torch.no_grad():\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    inputs = tokenizer(dataset[\"test\"][\"text\"], return_tensors=\"pt\", padding=True)\n",
    "    outputs = model_ft(**inputs)  # Remove device specification for automatic MPS handling\n",
    "    preds = outputs.logits.argmax(-1)\n",
    "    acc = (preds == dataset[\"test\"][\"label\"]).sum().float() / len(preds)\n",
    "    print(f\"Base Model Accuracy: {acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b47abf88",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "evaluate_base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7fe003",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "615b12c6",
   "metadata": {},
   "source": [
    "## Performing Inference with a PEFT Model\n",
    "\n",
    "TODO: In the cells below, load the saved PEFT model weights and evaluate the performance of the trained PEFT model. Be sure to compare the results to the results from prior to fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "863ec66e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06786775001091883"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timeit\n",
    "import torch\n",
    "import random\n",
    "x = torch.ones(50000000, device = 'mps')\n",
    "timeit.timeit(lambda: x * random.randint(0,100), number=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bc3a8147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04576800001086667"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(50000000, device = 'cpu')\n",
    "timeit.timeit(lambda: x * random.randint(0,100), number=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bc96905a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00019916699966415763"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(50000000, device = 'mps')\n",
    "timeit.timeit(lambda: x * random.randint(0,100), number=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.7 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "6b5b525088d6332c5cf70b03a9f5e180ca0f3c63042aef5ed677c6c58b7b131a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
